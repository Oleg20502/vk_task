{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "import emoji\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext.vocab\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'train_spam.csv'\n",
    "\n",
    "data_train_all = pd.read_csv(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train_all = data_train_all['text']\n",
    "labels_all = data_train_all['text_type']\n",
    "target_all = pd.Categorical(labels_all, categories=['ham', 'spam']).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь строится на основе тренировочных дынных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "ENGLISH_STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyperlink(words):\n",
    "    return  re.sub(r\"http\\S+\", \"\", words)\n",
    "\n",
    "def to_lower(words):\n",
    "    result = words.lower()\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    # result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    return re.sub(punctuation_pattern, ' ', words)\n",
    "\n",
    "def emoji_to_text(words):\n",
    "    return emoji.demojize(words)\n",
    "\n",
    "def remove_whitespace(words):\n",
    "    result = words.strip()\n",
    "    return result\n",
    "\n",
    "def replace_newline(words):\n",
    "    return words.replace('\\n', '')\n",
    "\n",
    "def remove_number(words, keyword=' NUMBER '):\n",
    "    result = re.sub(r'\\b\\w*\\d\\w*\\b', keyword, words)\n",
    "    return result\n",
    "\n",
    "def remove_currency(words, keyword=' CURRENCY '):\n",
    "    currency_pattern = r'[£$€₹]'\n",
    "    return re.sub(currency_pattern, keyword, words)\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
    "    return result\n",
    "\n",
    "def word_lemmatizer(words):\n",
    "    return [lemmatizer.lemmatize(s) for s in words]\n",
    "\n",
    "def join_words(words):\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(sentence):\n",
    "    preprocess_utils = [\n",
    "                        remove_hyperlink,\n",
    "                        replace_newline,\n",
    "                        to_lower,\n",
    "                        emoji_to_text,\n",
    "                        remove_currency,\n",
    "                        remove_number,\n",
    "                        # unidecode,   ####\n",
    "                        remove_punctuation,\n",
    "                        remove_whitespace,\n",
    "                        tokenizer.tokenize,\n",
    "                        # remove_stop_words, #####\n",
    "                        word_lemmatizer,   #####\n",
    "                    ]\n",
    "    for func in preprocess_utils:\n",
    "        sentence = func(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_preprocess = [\n",
    "    preprocess_pipeline(sent) for sent in texts_train_all.to_numpy()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_val, y_train, y_val = train_test_split(\n",
    "                                        data_train_preprocess,\n",
    "                                        target_all,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=42, \n",
    "                                        stratify=target_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_sentences):\n",
    "    counter = Counter()\n",
    "    for sentence in tokenized_sentences:\n",
    "        counter.update(sentence)\n",
    "    vocab = torchtext.vocab.vocab(counter, min_freq=3, specials=('<UNK>', '<SOS>', '<EOS>', '<PAD>'))\n",
    "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "    return vocab\n",
    "\n",
    "Vocab = build_vocab(texts_train)\n",
    "\n",
    "VOCAB_SIZE = len(Vocab)\n",
    "PAD_IDX = Vocab['<PAD>']\n",
    "SOS_IDX = Vocab['<SOS>']\n",
    "EOS_IDX = Vocab['<EOS>']\n",
    "UNK_IDX = Vocab['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(VOCAB_SIZE)\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data):\n",
    "    features, target = [], []\n",
    "    for text, y in data:\n",
    "        features.append(torch.tensor([Vocab['<SOS>']] + \\\n",
    "                                  Vocab.lookup_indices(text) + \\\n",
    "                                  [Vocab['<EOS>']],\n",
    "                                  dtype=torch.long))\n",
    "        target.append(torch.tensor(y, dtype=torch.long))\n",
    "    features = pad_sequence(features, padding_value=Vocab['<PAD>'], batch_first=True)\n",
    "    target = torch.tensor(target)\n",
    "    return features, target\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(list(zip(texts_train, y_train)), batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "val_loader = DataLoader(list(zip(texts_val, y_val)), batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamWordRNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embed_size, hidden_size, drop_p=0.5):\n",
    "        super(SpamWordRNN, self).__init__()\n",
    "\n",
    "        self.num_tokens = num_tokens\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emded_size = embed_size\n",
    "\n",
    "        self.embedding = nn.Embedding(num_tokens, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.dropout_embed = nn.Dropout(drop_p)\n",
    "        self.dropout_rnn = nn.Dropout(drop_p)\n",
    "        self.out = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout_embed(embedded)\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout_rnn(hidden[-1])\n",
    "        output = self.out(hidden)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, iterator, criterion, epoch, n_show = 50):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    current_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input, target = batch[0].to(DEVICE), batch[1].to(DEVICE)       \n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_loss = loss.item()\n",
    "        train_loss += current_loss\n",
    "\n",
    "        # if i % n_show == 0:\n",
    "        #     print(f'Epoch {epoch}, loss {current_loss:.3f}')\n",
    "        \n",
    "    return train_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm.tqdm(enumerate(iterator)):\n",
    "            input, target = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "\n",
    "            output = model(input)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def calc_metrics(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in tqdm.tqdm(enumerate(iterator)):\n",
    "            y_true.extend(target.detach().cpu().tolist())\n",
    "            input, target = input.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            output = model(input)\n",
    "\n",
    "            target_pred = torch.argmax(output, axis=1).detach().cpu().tolist()\n",
    "            y_pred.extend(target_pred)\n",
    "\n",
    "    return (\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        roc_auc_score(y_true, y_pred)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def count_parameters(m: torch.nn.Module, only_trainable: bool = True):\n",
    "    \"\"\"\n",
    "    Returns the total number of parameters used by `m` (only counting\n",
    "    shared parameters once); if `only_trainable` is True, then only\n",
    "    includes parameters with `requires_grad = True`\n",
    "    \"\"\"\n",
    "    parameters = list(m.parameters())\n",
    "    if only_trainable:\n",
    "        parameters = [p for p in parameters if p.requires_grad]\n",
    "    unique = {p.data_ptr(): p for p in parameters}.values()\n",
    "    return sum(p.numel() for p in unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3741442\n"
     ]
    }
   ],
   "source": [
    "EMB_SIZE = 256\n",
    "HID_SIZE = 256\n",
    "DROPOUT = 0.5\n",
    "\n",
    "\n",
    "model = SpamWordRNN(VOCAB_SIZE, EMB_SIZE, HID_SIZE, DROPOUT).to(DEVICE)\n",
    "print(f'Number of parameters: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 10\n",
    "n_show = 100\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "epoch = 0\n",
    "epoch_history = []\n",
    "\n",
    "accuracy_val = 0\n",
    "precision_val = 0\n",
    "recall_val = 0\n",
    "f1_val = 0\n",
    "roc_auc_val = 0\n",
    "roc_auc_val_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m      2\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mn_show\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion)\n\u001b[0;32m     13\u001b[0m     accuracy_val,\n",
      "Cell \u001b[1;32mIn[139], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, iterator, criterion, epoch, n_show)\u001b[0m\n\u001b[0;32m     10\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\OlegKashurin\\anaconda3\\envs\\ml_torch\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OlegKashurin\\anaconda3\\envs\\ml_torch\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OlegKashurin\\anaconda3\\envs\\ml_torch\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch + 1, N_epochs+1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model,\n",
    "                       optimizer,\n",
    "                       train_loader,\n",
    "                       criterion,\n",
    "                       epoch,\n",
    "                       n_show)\n",
    "    \n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    accuracy_val,\n",
    "    precision_val,\n",
    "    recall_val,\n",
    "    f1_val,\n",
    "    roc_auc_val = calc_metrics(model, val_loader)\n",
    "    roc_auc_val_history.append(roc_auc_val)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # if val_loss < best_valid_loss and val_loss < 2.3:\n",
    "    #     best_valid_loss = valid_loss\n",
    "    #     state = {\n",
    "    #             'epoch': epoch,\n",
    "    #             'state_dict': model.state_dict(),\n",
    "    #             'optimizer': optimizer.state_dict()}\n",
    "    #     torch.save(state, save_file)\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    val_history.append(val_loss)\n",
    "    epoch_history.append(epoch)\n",
    "    \n",
    "    clear_output(True)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'Train loss: {train_loss:.3f}; Val. loss: {val_loss:.3f}')\n",
    "    print(f'Accuracy {accuracy_val:.4f}, Precision {precision_val:.4f}, \\\n",
    "          Recall {recall_val:.4f}, f1 {f1_val:.4f}, ROC AUC {roc_auc_val:.4f}')\n",
    "    \n",
    "    plt.figure(figsize=[15, 4])\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss history\")\n",
    "    plt.plot(epoch_history, train_history, color='r', label='Train')\n",
    "    plt.plot(epoch_history, val_history, color='b', label='Val')\n",
    "    plt.legend()\n",
    "    # plt.yscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ROC AUC history\")\n",
    "    plt.plot(epoch_history, roc_auc_val_history, color='b')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
