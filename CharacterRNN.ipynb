{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "import emoji\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'train_spam.csv'\n",
    "\n",
    "data_train_all = pd.read_csv(file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train_all = data_train_all['text']\n",
    "labels_all = data_train_all['text_type']\n",
    "target_all = pd.Categorical(labels_all, categories=['ham', 'spam']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "ENGLISH_STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyperlink(words):\n",
    "    return  re.sub(r\"http\\S+\", \"\", words)\n",
    "\n",
    "def to_lower(words):\n",
    "    result = words.lower()\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    # result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    punctuation_pattern = r'[^\\w\\s]'\n",
    "    return re.sub(punctuation_pattern, ' ', words)\n",
    "\n",
    "def emoji_to_text(words):\n",
    "    return emoji.demojize(words)\n",
    "\n",
    "def remove_whitespace(words):\n",
    "    result = words.strip()\n",
    "    return result\n",
    "\n",
    "def replace_newline(words):\n",
    "    return words.replace('\\n', '')\n",
    "\n",
    "def remove_number(words, keyword=' NUMBER '):\n",
    "    result = re.sub(r'\\b\\w*\\d\\w*\\b', keyword, words)\n",
    "    return result\n",
    "\n",
    "def remove_currency(words, keyword=' CURRENCY '):\n",
    "    currency_pattern = r'[£$€₹]'\n",
    "    return re.sub(currency_pattern, keyword, words)\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
    "    return result\n",
    "\n",
    "def word_lemmatizer(words):\n",
    "    return [lemmatizer.lemmatize(s) for s in words]\n",
    "\n",
    "def join_words(words):\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(sentence):\n",
    "    preprocess_utils = [\n",
    "                        remove_hyperlink,\n",
    "                        replace_newline,\n",
    "                        to_lower,\n",
    "                        emoji_to_text,\n",
    "                        remove_currency,\n",
    "                        remove_number,\n",
    "                        unidecode,\n",
    "                        remove_punctuation,\n",
    "                        remove_whitespace,\n",
    "                    ]\n",
    "    for func in preprocess_utils:\n",
    "        sentence = func(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_preprocess = [\n",
    "    preprocess_pipeline(sent) for sent in texts_train_all.to_numpy()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_val, y_train, y_val = train_test_split(\n",
    "                                        data_train_preprocess,\n",
    "                                        target_all,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=42, \n",
    "                                        stratify=target_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamCharacterRNN(nn.Module):\n",
    "    def __init__(self, num_tokens, embed_size, hidden_size, drop_p=0.5):\n",
    "        super(SpamCharacterRNN, self).__init__()\n",
    "\n",
    "        self.num_tokens = num_tokens\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emded_size = embed_size\n",
    "\n",
    "        self.encoder = nn.Embedding(num_tokens, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.dropout_embed = nn.Dropout(drop_p)\n",
    "        self.dropout_rnn = nn.Dropout(drop_p)\n",
    "        self.out = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout_embed(embedded)\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout_rnn(hidden)\n",
    "        output = self.out(hidden)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, n_show = 50,\n",
    "                train_history=[], valid_history=[], bleu_history=[]):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    I_val = []\n",
    "    epoch_history = []\n",
    "    val_history = []\n",
    "    nf_val_history = []\n",
    "    bleu_scores = []\n",
    "    for i, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "        src = batch[0].to(DEVICE)\n",
    "        trg = batch[1].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        trg_output = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg_output)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_history.append(loss.detach().cpu().data.numpy())\n",
    "        \n",
    "        if (i+1) % n_show == 0:\n",
    "            I_val.append(i)\n",
    "            val_history.append(evaluate(model, val_loader, criterion))\n",
    "            \n",
    "            bleu_score, _1, _2 = calc_bleu(model, val_loader)\n",
    "            bleu_scores.append(bleu_score)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    \n",
    "            line_11, = ax[0].plot(epoch_history, label='train loss')\n",
    "            line_12, = ax[0].plot(I_val, val_history, label='val loss')\n",
    "            # line_13, = ax[0].plot(I_val, nf_val_history, label='no force val loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Loss')\n",
    "            ax[0].legend()\n",
    "            \n",
    "            if train_history != []:\n",
    "                ax[1].plot(train_history, label='Train loss')\n",
    "            if valid_history != []:\n",
    "                ax[1].plot(valid_history, label='Valid loss')\n",
    "            ax[1].legend()\n",
    "            ax[1].set_xlabel('# of epoch')\n",
    "            ax[1].set_title('Loss')\n",
    "            \n",
    "            fig.tight_layout()\n",
    "            clear_output(True)\n",
    "            plt.show()\n",
    "\n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch[0].to(DEVICE)\n",
    "            trg = batch[1].to(DEVICE)\n",
    "            \n",
    "            output = model(src)\n",
    "\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            trg_output = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg_output)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
